{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training examples\n",
      "10000 testing examples\n",
      "hidden layers [16, 16]\n",
      "learning rate 0.05\n"
     ]
    }
   ],
   "source": [
    "# build network\n",
    "import numpy as np\n",
    "import nn\n",
    "from nn.mnist_loader import MnistDataloader\n",
    "\n",
    "loader = MnistDataloader(\n",
    "  \"data/train-images-idx3-ubyte/train-images-idx3-ubyte\",\n",
    "  \"data/train-labels-idx1-ubyte/train-labels-idx1-ubyte\",\n",
    "  \"data/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\",\n",
    "  \"data/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\"\n",
    ")\n",
    "(x_train, y_train), (x_test, y_test) = loader.load_data()\n",
    "\n",
    "print(len(x_train), \"training examples\")\n",
    "print(len(x_test), \"testing examples\")\n",
    "\n",
    "hidden_layers = [16, 16]\n",
    "\n",
    "print(\"hidden layers\", hidden_layers)\n",
    "\n",
    "def pre_process_mnist(inp: np.ndarray) -> np.ndarray:\n",
    "  return np.concatenate(inp) / 255 # processing specific to mnist\n",
    "\n",
    "network = nn.Network(\n",
    "  x_train=x_train,\n",
    "  y_train=y_train,\n",
    "  hidden_layers=hidden_layers,\n",
    "  input_layer_size=len(np.concatenate(x_train[0])),\n",
    "  output_layer_size=10,\n",
    "  learning_rate=0.05,\n",
    "  pre_process=pre_process_mnist\n",
    ")\n",
    "\n",
    "print(\"learning rate\", network.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 batch(es) of size 20000\n",
      "starting training batch 1, using training slice [0, 20000]\n",
      "starting training batch 2, using training slice [20001, 40000]\n",
      "starting training batch 3, using training slice [40001, 60000]\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "batches = 3\n",
    "batch_size = 20000\n",
    "print(f\"training {batches} batch(es) of size {batch_size}\")\n",
    "network.train(batches, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9091 out of 10000 correct, score: 90.91%\n",
      "choice counts [1011, 1156, 928, 1072, 864, 855, 1037, 943, 1000, 1134]\n",
      "correct counts [980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009]\n"
     ]
    }
   ],
   "source": [
    "# test predictions\n",
    "total = len(x_test)\n",
    "correct = 0\n",
    "choice_counts = [0]*10\n",
    "correct_counts = [0]*10\n",
    "for i, test in enumerate(x_test):\n",
    "  label = y_test[i]\n",
    "  choice = network.predict_one(test)\n",
    "  choice_counts[choice] = choice_counts[choice]+1\n",
    "  correct_counts[label] = correct_counts[label]+1\n",
    "  if choice == label:\n",
    "    correct += 1\n",
    "\n",
    "print(f\"{correct} out of {total} correct, score: {(correct/total)*100}%\")\n",
    "print(\"choice counts\", choice_counts)\n",
    "print(\"correct counts\", correct_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
